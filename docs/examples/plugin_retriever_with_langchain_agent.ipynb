{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba5f8741",
   "metadata": {
    "id": "ba5f8741"
   },
   "source": [
    "# Plugin Retriever - Plug and Plai\n",
    "### Retrieve the optimal plugin to use with LLMs based on the user's message\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/edreisMD/plugnplai/blob/main/docs/examples/plugin_retriever_with_langchain_agent.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rPtygjemCQHE",
   "metadata": {
    "id": "rPtygjemCQHE"
   },
   "source": [
    "This notebook builds upon the idea of LangChain [tool retrieval](custom_agent_with_plugin_retrieval.html), but pulls all tools from `plugnplai` - a directory of AI Plugins. And abstracts the the instantiation of the vector database (plugin_retriever)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea4812c",
   "metadata": {
    "id": "fea4812c"
   },
   "source": [
    "## Set up environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca08be8",
   "metadata": {
    "id": "aca08be8"
   },
   "source": "Install plugnplai lib to get a list of active plugins from https://plugnplai.com directory"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "OKr4jRvDv4IJ",
   "metadata": {
    "id": "OKr4jRvDv4IJ"
   },
   "outputs": [],
   "source": [
    "!pip install plugnplai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "EiqnqramMcth",
   "metadata": {
    "id": "EiqnqramMcth"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_KEY\" # Copy your OpenAI Key from https://platform.openai.com/account/api-keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df0253f",
   "metadata": {
    "id": "6df0253f"
   },
   "source": [
    "## Set up plugins\n",
    "\n",
    "Load and index plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e0f7882",
   "metadata": {
    "id": "9e0f7882"
   },
   "outputs": [],
   "source": [
    "import plugnplai \n",
    "\n",
    "# Get all plugins from plugnplai.com\n",
    "urls = plugnplai.get_plugins()\n",
    "\n",
    "# Or get ChatGPT plugins - only ChatGPT verified plugins\n",
    "urls = plugnplai.get_plugins(filter = 'ChatGPT')\n",
    "\n",
    "# Or get working plugins - only tested plugins (in progress)\n",
    "urls = plugnplai.get_plugins(filter = 'working')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17362717",
   "metadata": {
    "id": "17362717"
   },
   "source": [
    "## Plugin Retriever\n",
    "\n",
    "We will use a vectorstore to create embeddings for each tool description. Then, for an incoming query we can create embeddings for that query and do a similarity search for relevant tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "EqHhHrPbrMMj",
   "metadata": {
    "id": "EqHhHrPbrMMj"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Initialize the PluginRetriever - Index the manifests in the vector database\n",
    "'''\n",
    "\n",
    "# Import PluginRetriever from plugnplai lib\n",
    "from plugnplai import PluginRetriever\n",
    "\n",
    "\n",
    "# Initialize directly from the provider website (https://plugnplai.com)\n",
    "# In this case it wouldn't be necessary to use any previous functions\n",
    "plugin_retriever = PluginRetriever.from_directory()\n",
    "\n",
    "# Or initialize from the manifests\n",
    "manifests = [plugnplai.spec_from_url(url)[0] for url in urls]\n",
    "plugin_retriever = PluginRetriever(manifests)\n",
    "\n",
    "# Or initialize directly from the ulrs, lets use this option to be consistent with the next steps\n",
    "plugin_retriever = PluginRetriever.from_urls(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FAA45e2Z6JZI",
   "metadata": {
    "id": "FAA45e2Z6JZI"
   },
   "source": [
    "## Define LangChain Agent with PluginsRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "V0SK-Pk4y-w2",
   "metadata": {
    "id": "V0SK-Pk4y-w2"
   },
   "source": [
    "Add plugin_retriever to LangChain Tools to call the custom retrieved APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5yVgfYRETCPG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5yVgfYRETCPG",
    "outputId": "e34f54b2-a64c-4d1a-d288-dab3c35b8e11"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain.tools.openapi.utils.openapi_utils:Attempting to load a Swagger 2.0 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
      "WARNING:langchain.tools.openapi.utils.openapi_utils:Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
      "WARNING:langchain.tools.openapi.utils.openapi_utils:Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
      "WARNING:langchain.tools.openapi.utils.openapi_utils:Attempting to load an OpenAPI 3.0.2 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
      "WARNING:langchain.tools.openapi.utils.openapi_utils:Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
      "WARNING:langchain.tools.openapi.utils.openapi_utils:Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
      "WARNING:langchain.tools.openapi.utils.openapi_utils:Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
      "WARNING:langchain.tools.openapi.utils.openapi_utils:Attempting to load an OpenAPI 3.0.2 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
      "WARNING:langchain.tools.openapi.utils.openapi_utils:Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
      "WARNING:langchain.tools.openapi.utils.openapi_utils:Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
      "WARNING:langchain.tools.openapi.utils.openapi_utils:Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain import OpenAI, SerpAPIWrapper, LLMChain\n",
    "from typing import List, Union\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "from langchain.agents.agent_toolkits import NLAToolkit\n",
    "from langchain.tools.plugin import AIPlugin\n",
    "import re\n",
    "\n",
    "# Load LangChain AIPlugin Objects  \n",
    "AI_PLUGINS = [AIPlugin.from_url(url + \"/.well-known/ai-plugin.json\") for url in urls]\n",
    "\n",
    "# Define llm\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "toolkits_dict = {plugin.name_for_model: \n",
    "                 NLAToolkit.from_llm_and_ai_plugin(llm, plugin)\n",
    "                 for plugin in AI_PLUGINS}\n",
    "\n",
    "def get_tools(query):\n",
    "    # Get documents, which contain the Plugins to use\n",
    "    docs = plugin_retriever.retrieve_names(query)\n",
    "    # Get the toolkits, one for each plugin\n",
    "    tool_kits = [toolkits_dict[d] for d in docs]\n",
    "    # Get the tools: a separate NLAChain for each endpoint\n",
    "    tools = []\n",
    "    for tk in tool_kits:\n",
    "        tools.extend(tk.nla_tools)\n",
    "    return tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7699afd7",
   "metadata": {
    "id": "7699afd7"
   },
   "source": [
    "\n",
    "We can now test this retriever to see if it seems to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "425f2886",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "425f2886",
    "outputId": "3cb5fc3c-4eb8-4669-c086-ad1310ea02f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Milo.askMilo',\n",
       " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.search_all_actions',\n",
       " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.preview_a_zap',\n",
       " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.get_configuration_link',\n",
       " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.list_exposed_actions',\n",
       " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.get_execution_log_endpoint',\n",
       " 'SchoolDigger_API_V2.0.Autocomplete_GetSchools',\n",
       " 'SchoolDigger_API_V2.0.Districts_GetAllDistricts2',\n",
       " 'SchoolDigger_API_V2.0.Districts_GetDistrict2',\n",
       " 'SchoolDigger_API_V2.0.Rankings_GetSchoolRank2',\n",
       " 'SchoolDigger_API_V2.0.Rankings_GetRank_District',\n",
       " 'SchoolDigger_API_V2.0.Schools_GetAllSchools20',\n",
       " 'SchoolDigger_API_V2.0.Schools_GetSchool20',\n",
       " 'Open_AI_Klarna_product_Api.productsUsingGET']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = get_tools(\"what could I do today with my kiddo\")\n",
    "[t.name for t in tools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3aa88768",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3aa88768",
    "outputId": "e4e69afd-1fdc-4421-a10a-eca22255a26c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Open_AI_Klarna_product_Api.productsUsingGET',\n",
       " 'Milo.askMilo',\n",
       " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.search_all_actions',\n",
       " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.preview_a_zap',\n",
       " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.get_configuration_link',\n",
       " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.list_exposed_actions',\n",
       " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.get_execution_log_endpoint',\n",
       " 'SchoolDigger_API_V2.0.Autocomplete_GetSchools',\n",
       " 'SchoolDigger_API_V2.0.Districts_GetAllDistricts2',\n",
       " 'SchoolDigger_API_V2.0.Districts_GetDistrict2',\n",
       " 'SchoolDigger_API_V2.0.Rankings_GetSchoolRank2',\n",
       " 'SchoolDigger_API_V2.0.Rankings_GetRank_District',\n",
       " 'SchoolDigger_API_V2.0.Schools_GetAllSchools20',\n",
       " 'SchoolDigger_API_V2.0.Schools_GetSchool20']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = get_tools(\"what shirts can i buy?\")\n",
    "[t.name for t in tools]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7a075c",
   "metadata": {
    "id": "2e7a075c"
   },
   "source": [
    "## Prompt Template\n",
    "\n",
    "The prompt template is pretty standard, because we're not actually changing that much logic in the actual prompt template, but rather we are just changing how retrieval is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "339b1bb8",
   "metadata": {
    "id": "339b1bb8"
   },
   "outputs": [],
   "source": [
    "# Set up the base template\n",
    "template = \"\"\"Answer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Arg\"s\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1583acdc",
   "metadata": {
    "id": "1583acdc"
   },
   "source": [
    "The custom prompt template now has the concept of a tools_getter, which we call on the input to select the tools to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd969d31",
   "metadata": {
    "id": "fd969d31"
   },
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "# Set up a prompt template\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    ############## NEW ######################\n",
    "    # The list of tools available\n",
    "    tools_getter: Callable\n",
    "    \n",
    "    def format(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        ############## NEW ######################\n",
    "        tools = self.tools_getter(kwargs[\"input\"])\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in tools])\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in tools])\n",
    "        return self.template.format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "798ef9fb",
   "metadata": {
    "id": "798ef9fb"
   },
   "outputs": [],
   "source": [
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools_getter=get_tools,\n",
    "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "    # This includes the `intermediate_steps` variable because that is needed\n",
    "    input_variables=[\"input\", \"intermediate_steps\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3a1af3",
   "metadata": {
    "id": "ef3a1af3"
   },
   "source": [
    "## Output Parser\n",
    "\n",
    "The output parser is unchanged from the previous notebook, since we are not changing anything about the output format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c6fe0d3",
   "metadata": {
    "id": "7c6fe0d3"
   },
   "outputs": [],
   "source": [
    "class CustomOutputParser(AgentOutputParser):\n",
    "    \n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d278706a",
   "metadata": {
    "id": "d278706a"
   },
   "outputs": [],
   "source": [
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170587b1",
   "metadata": {
    "id": "170587b1"
   },
   "source": [
    "## Set up LLM, stop sequence, and the agent\n",
    "\n",
    "Also the same as the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9d4c374",
   "metadata": {
    "id": "f9d4c374"
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b1cc2a2",
   "metadata": {
    "id": "9b1cc2a2"
   },
   "outputs": [],
   "source": [
    "# LLM chain consisting of the LLM and a prompt\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4f5092f",
   "metadata": {
    "id": "e4f5092f"
   },
   "outputs": [],
   "source": [
    "tool_names = [tool.name for tool in tools]\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain, \n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"], \n",
    "    allowed_tools=tool_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8a5326",
   "metadata": {
    "id": "aa8a5326"
   },
   "source": [
    "## Use the Agent\n",
    "\n",
    "Now we can use it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "490604e9",
   "metadata": {
    "id": "490604e9"
   },
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "653b1617",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "id": "653b1617",
    "outputId": "3d870dbd-9fba-465b-a2f3-e507735a182f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mThought: I need to find a way to get product information\n",
      "Action: Open_AI_Klarna_product_Api.productsUsingGET\n",
      "Action Input: shirts\u001B[0m\n",
      "\n",
      "Observation:\u001B[36;1m\u001B[1;3mI found 10 shirts from the API response. They range in price from $13.94 to $491.00 and come in a variety of materials, sizes, colors, and styles.\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m I now know the final answer\n",
      "Final Answer: Arg, ye can buy any of these 10 shirts from the API response. They range in price from $13.94 to $491.00 and come in a variety of materials, sizes, colors, and styles.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Arg, ye can buy any of these 10 shirts from the API response. They range in price from $13.94 to $491.00 and come in a variety of materials, sizes, colors, and styles.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"what shirts can i buy?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dvcVS5dLJQYn",
   "metadata": {
    "id": "dvcVS5dLJQYn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
